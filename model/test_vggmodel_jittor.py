import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from RepVGG_model_jittor import RepVGG_Model
import jittor as jt
import jittor.nn as nn
from jittor import optim
from jittor.dataset import CIFAR10
import time
import copy

# å¯ç”¨ CUDA
jt.flags.use_cuda = 1

def test_repvgg_cifar10():
    print(f"Using device: {'CUDA' if jt.flags.use_cuda else 'CPU'}")
    
    # æ•°æ®é¢„å¤„ç† - Jittor ç‰ˆæœ¬ (ä¿®å¤å)
    normalize = jt.transform.ImageNormalize(
        mean=[0.4914, 0.4822, 0.4465], 
        std=[0.2023, 0.1994, 0.2010]
    )
    
    # è®­ç»ƒæ•°æ®å˜æ¢ - ä¿®å¤ RandomCrop å‚æ•°
    train_transform = jt.transform.Compose([
        jt.transform.Resize((36, 36)),  # å…ˆæ”¾å¤§
        jt.transform.RandomCrop(32),    # ç„¶åéšæœºè£å‰ªåˆ°32x32
        jt.transform.RandomHorizontalFlip(0.5),
        jt.transform.ToTensor(),
        normalize
    ])
    
    # æµ‹è¯•æ•°æ®å˜æ¢
    test_transform = jt.transform.Compose([
        jt.transform.ToTensor(),
        normalize
    ])
    
    # åŠ è½½æ•°æ®é›†
    train_dataset = CIFAR10(train=True, transform=train_transform, download=True)
    test_dataset = CIFAR10(train=False, transform=test_transform)
    
    train_loader = train_dataset.set_attrs(batch_size=128, shuffle=True)
    test_loader = test_dataset.set_attrs(batch_size=256, shuffle=False)
    
    print("Creating RepVGG model for CIFAR-10...")
    model = RepVGG_Model(
        channel_scale_A=0.5,    
        channel_scale_B=1.0,
        group_conv=1,          
        classify_classes=10,     
        model_type='A'
    )
    
    # è®¡ç®—å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters() if hasattr(p, 'numel'))
    print(f"Model parameters: {total_params:,}")
    
    print("\n=== Training Phase ===")
    num_epochs = 20
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)
    
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            # å‰å‘ä¼ æ’­
            output = model(data)
            loss = nn.cross_entropy_loss(output, target)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            optimizer.backward(loss)
            optimizer.step()
            
            total_loss += loss.item()
            pred = jt.argmax(output, dim=1)[0]
            correct += (pred == target).sum().item()
            total += target.shape[0]
            
            if batch_idx % 100 == 0:
                print(f'Epoch {epoch+1}, Batch {batch_idx}, Loss: {loss.item():.4f}')
        
        accuracy = 100. * correct / total
        print(f'Epoch {epoch+1} - Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%')
    
    print("\n=== Testing Original Model ===")
    model.eval()
    test_accuracy_orig = test_model(model, test_loader)
    
    print("\n=== Verifying Conversion ===")
    verify_conversion(model)
    
    print("\n=== Converting to Inference Mode ===")
    model.convert_to_infer()
    
    print("=== Testing Converted Model ===")
    model.eval()
    test_accuracy_infer = test_model(model, test_loader)
    
    print(f"\n=== Results ===")
    print(f"Original accuracy: {test_accuracy_orig:.2f}%")
    print(f"Inference accuracy: {test_accuracy_infer:.2f}%")
    print(f"Difference: {abs(test_accuracy_orig - test_accuracy_infer):.4f}%")

def test_model(model, test_loader):
    model.eval()
    correct = 0
    total = 0
    
    with jt.no_grad():
        for data, target in test_loader:
            output = model(data)
            pred = jt.argmax(output, dim=1)[0]
            correct += (pred == target).sum().item()
            total += target.shape[0]
    
    accuracy = 100. * correct / total
    print(f'Test Accuracy: {accuracy:.2f}%')
    return accuracy

def verify_conversion(model):
    """éªŒè¯è½¬æ¢å‰åä¸€è‡´æ€§"""
    model.eval()
    test_input = jt.randn(4, 3, 32, 32)
    
    with jt.no_grad():
        output_before = model(test_input)
    
    # æ·±æ‹·è´æ¨¡å‹
    model_copy = copy.deepcopy(model)
    model_copy.convert_to_infer()
    
    with jt.no_grad():
        output_after = model_copy(test_input)
    
    diff = jt.abs(output_before - output_after).max().item()
    print(f"diff : {diff:.6f}")

def simple_test():
    """ç®€å•åŠŸèƒ½æµ‹è¯•"""
    print("ğŸ§ª Simple functionality test")
    print("="*50)
    
    # åˆ›å»ºå°æ¨¡å‹è¿›è¡Œå¿«é€Ÿæµ‹è¯•
    model = RepVGG_Model(
        channel_scale_A=0.25,    # æ›´å°çš„æ¨¡å‹
        channel_scale_B=0.5,
        group_conv=1,          
        classify_classes=10,     
        model_type='A'
    )
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    test_input = jt.randn(2, 3, 32, 32)
    
    print("è®­ç»ƒæ¨¡å¼æµ‹è¯•:")
    model.train()
    output_train = model(test_input)
    print(f"è¾“å…¥å½¢çŠ¶: {test_input.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶: {output_train.shape}")
    
    print("\næ¨ç†æ¨¡å¼æµ‹è¯•:")
    model.eval()
    output_eval_before = model(test_input)
    
    # è½¬æ¢ä¸ºæ¨ç†æ¨¡å¼
    model.convert_to_infer()
    output_eval_after = model(test_input)
    
    # æ£€æŸ¥ä¸€è‡´æ€§
    diff = jt.abs(output_eval_before - output_eval_after).max().item()
    print(f"è½¬æ¢å‰åå·®å¼‚: {diff:.2e}")
    
    if diff < 1e-5:
        print("âœ… ç®€å•æµ‹è¯•é€šè¿‡")
    else:
        print("âš ï¸ è½¬æ¢å­˜åœ¨å·®å¼‚ï¼Œä½†å¯èƒ½åœ¨å¯æ¥å—èŒƒå›´å†…")

def performance_comparison():
    """æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    print("\nğŸƒ Performance comparison test")
    print("="*50)
    
    model = RepVGG_Model(
        channel_scale_A=0.5,
        channel_scale_B=1.0,
        group_conv=1,
        classify_classes=10,
        model_type='A'
    )
    
    test_input = jt.randn(8, 3, 32, 32)
    num_runs = 50
    
    # è®­ç»ƒæ¨¡å¼æ€§èƒ½
    model.eval()
    jt.sync_all()
    start_time = time.time()
    
    with jt.no_grad():
        for _ in range(num_runs):
            _ = model(test_input)
    
    jt.sync_all()
    train_time = time.time() - start_time
    
    # æ¨ç†æ¨¡å¼æ€§èƒ½
    model.convert_to_infer()
    jt.sync_all()
    start_time = time.time()
    
    with jt.no_grad():
        for _ in range(num_runs):
            _ = model(test_input)
    
    jt.sync_all()
    infer_time = time.time() - start_time
    
    print(f"è®­ç»ƒæ¨¡å¼å¹³å‡æ—¶é—´: {train_time/num_runs*1000:.2f} ms")
    print(f"æ¨ç†æ¨¡å¼å¹³å‡æ—¶é—´: {infer_time/num_runs*1000:.2f} ms")
    if infer_time > 0:
        print(f"åŠ é€Ÿæ¯”: {train_time/infer_time:.2f}x")

# ç®€åŒ–çš„æ•°æ®å˜æ¢ç‰ˆæœ¬
def simple_test_with_data():
    """ä½¿ç”¨ç®€åŒ–æ•°æ®å˜æ¢çš„æµ‹è¯•"""
    print("ğŸ§ª Simple test with CIFAR10 data")
    print("="*50)
    
    # ç®€åŒ–çš„æ•°æ®å˜æ¢
    simple_transform = jt.transform.Compose([
        jt.transform.ToTensor(),
        jt.transform.ImageNormalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])
    
    # åŠ è½½å°‘é‡æ•°æ®è¿›è¡Œæµ‹è¯•
    test_dataset = CIFAR10(train=False, transform=simple_transform)
    test_loader = test_dataset.set_attrs(batch_size=32, shuffle=False)
    
    # åˆ›å»ºå°æ¨¡å‹
    model = RepVGG_Model(
        channel_scale_A=0.25,
        channel_scale_B=0.5,
        group_conv=1,
        classify_classes=10,
        model_type='A'
    )
    
    print("æµ‹è¯•æ•°æ®åŠ è½½...")
    # åªæµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
    for data, target in test_loader:
        print(f"æ•°æ®å½¢çŠ¶: {data.shape}, æ ‡ç­¾å½¢çŠ¶: {target.shape}")
        
        # å‰å‘ä¼ æ’­æµ‹è¯•
        model.eval()
        with jt.no_grad():
            output = model(data)
        print(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        # è½¬æ¢æµ‹è¯•
        model.convert_to_infer()
        with jt.no_grad():
            output_infer = model(data)
        print(f"æ¨ç†æ¨¡å¼è¾“å‡ºå½¢çŠ¶: {output_infer.shape}")
        
        print("âœ… æ•°æ®æµ‹è¯•é€šè¿‡")
        break  # åªæµ‹è¯•ç¬¬ä¸€ä¸ªæ‰¹æ¬¡

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æµ‹è¯• Jittor RepVGG Model")
    print("="*60)
    
    # é€‰æ‹©æµ‹è¯•æ¨¡å¼
    test_mode = input("é€‰æ‹©æµ‹è¯•æ¨¡å¼ (1: ç®€å•æµ‹è¯•, 2: æ€§èƒ½æµ‹è¯•, 3: å®Œæ•´è®­ç»ƒ, 4: æ•°æ®æµ‹è¯•): ")
    
    if test_mode == "1":
        simple_test()
    elif test_mode == "2":
        simple_test()
        performance_comparison()
    elif test_mode == "3":
        test_repvgg_cifar10()
    elif test_mode == "4":
        simple_test_with_data()
    else:
        print("è¿è¡Œç®€å•æµ‹è¯•...")
        simple_test()
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")